{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "Takes in a .txt of the course names, outputs unigram, bigram, and trigram probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "courses = []\n",
    "with open('/Users/ericknudson/Desktop/Data Science Projects/SOM Course Name Generator/coursenames16.txt', encoding='utf-16') as fp:\n",
    "    courses = fp.readlines()\n",
    "courses = [x.strip('\\\"') for x in courses] \n",
    "mgt = re.compile(\"MGT*\")\n",
    "mgtcourses = []\n",
    "for course in courses:\n",
    "    if mgt.match(course):\n",
    "        mgtcourses.append(course)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgtcourses = [x.split() for x in mgtcourses]\n",
    "nums = []\n",
    "for i, course in enumerate(mgtcourses):\n",
    "    nums.append(course[1])\n",
    "    mgtcourses[i] = course[2:]\n",
    "nums.remove(\"Successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgtcourses = [\" \".join(x) for x in mgtcourses]\n",
    "uniquecourses = set(mgtcourses)\n",
    "uniquecourses = list(uniquecourses)\n",
    "uniquecourses.remove(\"(01) MGT 857: Digital Strategy\")\n",
    "uniquecourses.append(\"Digital Strategy\")\n",
    "uniquecourses.remove(\"MGT 697: Capitalism and its Critics\")\n",
    "uniquecourses.append(\"Capitalism and its Critics\")\n",
    "mgt = re.compile(\"GNAM*\")\n",
    "for i, course in enumerate(uniquecourses):\n",
    "    if mgt.match(course):\n",
    "#        print(course)\n",
    "        course = course.split(\":\")\n",
    "        course = course[1].strip('\\\"')\n",
    "        uniquecourses[i] = course\n",
    "uniquecourses = [x.strip(\" \") for x in uniquecourses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hbscourses = []\n",
    "with open('/Users/ericknudson/Desktop/Data Science Projects/SOM Course Name Generator/HBScourses.txt') as fp:\n",
    "    hbscourses = fp.readlines()\n",
    "hbscourses = set(hbscourses)\n",
    "hbscourses = list(hbscourses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "courselist = hbscourses + uniquecourses\n",
    "for i, course in enumerate(courselist):\n",
    "    course = course.replace(u'\\xa0', u' ')\n",
    "    course = course.replace(u'Application Only', u'')\n",
    "    course = course.replace(u'Americaâ€™s', u'America\\'s')\n",
    "    course = re.sub(r' and ', ' & ', course)\n",
    "    courselist[i] = course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizedcourses = [x.title() for x in courselist]\n",
    "tokenizedcourses = [re.findall(r\"[\\w'-]+|[,!?:;&]\", x) for x in tokenizedcourses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "w = csv.writer(open(\"tokenizedcourses.csv\",\"w\"))\n",
    "for i in tokenizedcourses:\n",
    "    w.writerow(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizedcourses2 = []\n",
    "with open('tokenizedcourses.csv') as csv_file:\n",
    "    csv_reader = csv.reader(x.replace('\\0', '') for x in csv_file)\n",
    "    for row in csv_reader:\n",
    "        tokenizedcourses2.append(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate n-gram probability dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "START_SYMBOL = '*'\n",
    "STOP_SYMBOL = 'STOP'\n",
    "\n",
    "def calc_probabilities(training_corpus):\n",
    "    unigram_counts = Counter()\n",
    "    bigram_counts = Counter()\n",
    "    trigram_counts = Counter()\n",
    "    for course in training_corpus:\n",
    "\n",
    "        #tokens = course.split()\n",
    "        course = course.title()\n",
    "        tokens = re.findall(r\"[\\w'-]+|[,!?:;&]\", course)\n",
    "\n",
    "        unigram_tokens = tokens + [STOP_SYMBOL]\n",
    "        unigram_counts.update(unigram_tokens)\n",
    "\n",
    "        bigram_tokens =  [START_SYMBOL] + tokens + [STOP_SYMBOL]\n",
    "        bigram_tuples = list(nltk.bigrams(bigram_tokens))\n",
    "        bigram_counts.update(bigram_tuples)\n",
    "\n",
    "        trigram_tokens =  [START_SYMBOL] + [START_SYMBOL] + tokens + [STOP_SYMBOL]\n",
    "        trigram_tuples = list(nltk.trigrams(trigram_tokens))\n",
    "        trigram_counts.update(trigram_tuples)\n",
    "\n",
    "    n_unigrams = sum(unigram_counts.values())\n",
    "    n_bigrams = sum(bigram_counts.values())\n",
    "    n_trigrams = sum(trigram_counts.values())\n",
    "\n",
    "    unigram_counts = dict(unigram_counts)\n",
    "    bigram_counts = dict(bigram_counts)\n",
    "    trigram_counts = dict(trigram_counts)\n",
    "\n",
    "    #unigram_probabilities = {k:math.log(x / n_unigrams,2) for (k,x) in unigram_counts.items()}\n",
    "    unigram_probabilities = {}\n",
    "    for (unigram, count) in unigram_counts.items():\n",
    "        #prob = math.log(count,2) - math.log(n_unigrams,2)\n",
    "        prob = count / n_unigrams\n",
    "        unigram_probabilities.update({unigram: prob})\n",
    "\n",
    "    bigram_probabilities = {}\n",
    "    for (bigram, count) in bigram_counts.items():\n",
    "        if bigram[0] == START_SYMBOL:\n",
    "            #prob = math.log(count,2) - math.log(unigram_counts[STOP_SYMBOL],2) #set denom to number of sentences\n",
    "            prob = count / unigram_counts[STOP_SYMBOL]\n",
    "            bigram_probabilities.update({bigram: prob})\n",
    "        else:\n",
    "            #prob = math.log(count,2) - math.log(unigram_counts[bigram[0]],2)\n",
    "            prob = count / n_bigrams\n",
    "            bigram_probabilities.update({bigram: prob})\n",
    "\n",
    "    trigram_probabilities = {}\n",
    "    for (trigram, count) in trigram_counts.items():\n",
    "        if trigram[0:2] == (START_SYMBOL,START_SYMBOL):\n",
    "            #prob = math.log(count,2) - math.log(unigram_counts[STOP_SYMBOL],2) #set denom to number of sentences\n",
    "            prob = prob = count / unigram_counts[STOP_SYMBOL]\n",
    "            trigram_probabilities.update({trigram: prob})\n",
    "        else:\n",
    "            #prob = math.log(count,2) - math.log(bigram_counts[trigram[0:2]],2)\n",
    "            prob = count / n_trigrams\n",
    "            trigram_probabilities.update({trigram: prob})\n",
    "    return unigram_probabilities, bigram_probabilities, trigram_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_probabilities, bigram_probabilities, trigram_probabilities = calc_probabilities(courselist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-Gram Name Generators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unigram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MGT 955-01 For New Evolution Fund Strategic'"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy.random import choice\n",
    "output = []\n",
    "next_token = \"\"\n",
    "while next_token != 'STOP':\n",
    "    next_token = choice(np.array(list(unigram_probabilities.keys())), 1, p = np.array(list(unigram_probabilities.values())))[0]\n",
    "    output.append(next_token)\n",
    "output = output[0:-1] #remove stop\n",
    "new_name = \" \".join(output)\n",
    "num = choice(nums,1)[0]\n",
    "new_name = \"MGT \" + num + \" \" + new_name \n",
    "new_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bigram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import choice\n",
    "def gen_bigram_course(*args):\n",
    "    bigram_probabilities = args[0]\n",
    "    tokenized_courses = args[1]\n",
    "    output = [\"*\"]\n",
    "    next_token = \"\"\n",
    "    i = 1\n",
    "    while next_token != 'STOP':\n",
    "        current_history = output[i-1]\n",
    "        possible_bigrams = [(key, value) for key, value in bigram_probabilities.items() if key[0] == current_history]\n",
    "        bigrams = [x[0] for x in possible_bigrams]\n",
    "        bigrams = [x[1] for x in bigrams]\n",
    "        probs = [x[1] for x in possible_bigrams]\n",
    "        sprobs = np.sum(probs)\n",
    "        probs = np.divide(probs,sprobs)\n",
    "        if i == 1:\n",
    "            next_token = choice(np.array(bigrams), 1)[0]\n",
    "        else:\n",
    "            #next_token = choice(np.array(bigrams), 1)[0]\n",
    "            next_token = choice(np.array(bigrams), 1, p = np.array(probs))[0]\n",
    "        #look back 2, choose bigram based on distribution of bigrams with those first two words in common\n",
    "        output.append(next_token)\n",
    "        i = i + 1\n",
    "    output = output[1:-1] #remove stop\n",
    "    if output in tokenized_courses:\n",
    "        print(\"dupe:\", output)\n",
    "        output = gen_bigram_course(bigram_probabilities, tokenized_courses)\n",
    "    return(output)\n",
    "        \n",
    "def put_course_name_together(output):\n",
    "    new_name = \" \".join(output)\n",
    "    new_name = new_name.replace(\" ,\",\",\")\n",
    "    new_name = new_name.replace(\" :\",\":\")\n",
    "    new_name = new_name.replace(\" ?\",\"?\")\n",
    "    num = choice(nums,1)[0]\n",
    "    new_name = \"MGT \" + num + \" \" + new_name \n",
    "    return(new_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MGT 612-01 Building & Literature\n"
     ]
    }
   ],
   "source": [
    "output = gen_bigram_course(bigram_probabilities, tokenizedcourses)\n",
    "course = put_course_name_together(output)\n",
    "print(course)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "courselis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_trigram_course(*args):\n",
    "    trigram_probabilities = args[0]\n",
    "    tokenized_courses = args[1]\n",
    "    output = [\"*\", \"*\"]\n",
    "    next_token = \"\"\n",
    "    i = 2\n",
    "    while next_token != 'STOP':\n",
    "        current_history = tuple(output[i-2:i])\n",
    "        possible_trigrams = [(key, value) for key, value in trigram_probabilities.items() if key[0:2] == current_history]\n",
    "        trigrams = [x[0][2] for x in possible_trigrams]\n",
    "        probs = [x[1] for x in possible_trigrams]\n",
    "        sprobs = np.sum(probs)\n",
    "        probs = np.divide(probs,sprobs)\n",
    "        if i == 2:\n",
    "            next_token = choice(np.array(trigrams), 1)[0]\n",
    "        else:\n",
    "            #next_token = choice(np.array(trigrams), 1, p = np.array(probs))[0]\n",
    "            next_token = choice(np.array(trigrams), 1)[0]\n",
    "        output.append(next_token)\n",
    "        i = i + 1\n",
    "    output = output[2:-1] #remove stop\n",
    "    if output in tokenized_courses:\n",
    "        print(\"dupe:\", output)\n",
    "        output = gen_course(bigram_probabilities, tokenized_courses)\n",
    "    return(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dupe: ['Product', 'Management', '101']\n",
      "dupe: ['Investment', 'Management']\n",
      "dupe: ['Interpersonal', 'Dynamics']\n",
      "MGT 873-01 Inclusive Economic Development\n"
     ]
    }
   ],
   "source": [
    "output = gen_trigram_course(trigram_probabilities, tokenizedcourses)\n",
    "course = put_course_name_together(output)\n",
    "print(course)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Databases for Web App\n",
    "\n",
    "bigrams and nums to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "w = csv.writer(open(\"bigram_probabilities.csv\",\"w\"))\n",
    "for (key, val) in bigram_probabilities.items():\n",
    "    w.writerow([key[0], key[1], val])\n",
    "w = csv.writer(open(\"nums.csv\",\"w\"))\n",
    "for i in nums:\n",
    "    w.writerow(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_probabilities[(\"&\",\"Society\")] = bigram_probabilities[(\"&\",\"Society\")] * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007782101167315175"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_probabilities[(\"&\",\"Society\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
